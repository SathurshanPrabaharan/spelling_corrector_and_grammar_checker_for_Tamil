{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ABhrE6tkP7d",
        "outputId": "cb16ea3e-88fe-4fd5-9e40-0549fe801f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: install keras\n",
        "\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJwVhLuIlFCW",
        "outputId": "ce9474ec-555e-4333-9c3a-edf9d7a35e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import re\n",
        "\n",
        "# 1. Load and preprocess the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AI/Error Annotated Corpus.csv\")\n",
        "\n",
        "# Use relevant columns and clean missing values\n",
        "df_cleaned = df[['Error word & consecutive word', 'Annotation']].dropna()\n",
        "df_cleaned.columns = ['text', 'label']\n",
        "\n",
        "# Clean Tamil text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0B80-\\u0BFF\\s]', '', text)  # Keep only Tamil characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "df_cleaned['text'] = df_cleaned['text'].apply(clean_text)\n",
        "\n",
        "texts = df_cleaned['text'].values\n",
        "labels = df_cleaned['label'].values\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Tokenize Tamil text with subword tokenization (using SentencePiece)\n",
        "import sentencepiece as spm\n",
        "\n",
        "# Train a SentencePiece model if not already trained\n",
        "with open(\"tamil_text.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(texts))\n",
        "\n",
        "spm.SentencePieceTrainer.train(input='tamil_text.txt', model_prefix='tamil', vocab_size=5000)\n",
        "tokenizer = spm.SentencePieceProcessor(model_file='tamil.model')\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = [tokenizer.encode_as_ids(text) for text in texts]\n",
        "\n",
        "# Set a fixed max length for padding\n",
        "max_length = 100\n",
        "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Define the model\n",
        "vocab_size = tokenizer.vocab_size()\n",
        "\n",
        "input_layer = Input(shape=(max_length,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=256)(input_layer)\n",
        "lstm_layer = Bidirectional(LSTM(128, return_sequences=False))(embedding_layer)\n",
        "dropout_layer = Dropout(0.5)(lstm_layer)\n",
        "output_layer = Dense(len(label_encoder.classes_), activation=\"softmax\")(dropout_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Train the model with early stopping and learning rate scheduler\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "model.summary()\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n",
        "\n",
        "# 4. Evaluate the model\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "# Get unique labels in y_test\n",
        "unique_classes_in_test = np.unique(y_test)\n",
        "\n",
        "# Generate the classification report with only the present classes\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    labels=unique_classes_in_test,  # Use only labels present in y_test\n",
        "    target_names=[label_encoder.classes_[i] for i in unique_classes_in_test]\n",
        "))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred, labels=unique_classes_in_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4_RMG-t4kjhc",
        "outputId": "ce917729-4399-488f-a338-0019cc7f15e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m394,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │           \u001b[38;5;34m6,168\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,168</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,680,408\u001b[0m (6.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,680,408</span> (6.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,680,408\u001b[0m (6.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,680,408</span> (6.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 470ms/step - accuracy: 0.2535 - loss: 2.4827 - val_accuracy: 0.2749 - val_loss: 2.1467 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 466ms/step - accuracy: 0.3367 - loss: 2.1395 - val_accuracy: 0.4129 - val_loss: 1.8439 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 460ms/step - accuracy: 0.6323 - loss: 1.3579 - val_accuracy: 0.5386 - val_loss: 1.6503 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 485ms/step - accuracy: 0.8488 - loss: 0.6253 - val_accuracy: 0.5224 - val_loss: 1.8299 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 464ms/step - accuracy: 0.9253 - loss: 0.3063 - val_accuracy: 0.5249 - val_loss: 1.9832 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 464ms/step - accuracy: 0.9663 - loss: 0.1609 - val_accuracy: 0.5323 - val_loss: 2.1808 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 477ms/step - accuracy: 0.9793 - loss: 0.1058 - val_accuracy: 0.5299 - val_loss: 2.2557 - learning_rate: 5.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 463ms/step - accuracy: 0.9834 - loss: 0.0765 - val_accuracy: 0.5323 - val_loss: 2.3237 - learning_rate: 5.0000e-04\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "              அவை       0.00      0.00      0.00         6\n",
            "               ஆக       0.57      0.35      0.43        37\n",
            "               ஆன       0.00      0.00      0.00         1\n",
            "இரண்டாம் வேற்றுமை       0.59      0.61      0.60        80\n",
            "          இருந்து       0.00      0.00      0.00         2\n",
            "      உடன்படுமெய்       0.00      0.00      0.00         4\n",
            "      உயிரெழுத்து       0.00      0.00      0.00         2\n",
            "        ஒருங்குறி       0.00      0.00      0.00         5\n",
            "              ஓர்       0.00      0.00      0.00        10\n",
            "            சந்தி       0.50      0.72      0.59       239\n",
            "             சுழி       0.00      0.00      0.00         1\n",
            "  சுழி (அறியாமல்)       0.00      0.00      0.00        15\n",
            "      தட்டுப்பிழை       0.48      0.63      0.55       263\n",
            "நான்காம் வேற்றுமை       0.66      0.60      0.63        62\n",
            "        புணர்ச்சி       0.00      0.00      0.00         2\n",
            "       பெயரெச்சம்       0.00      0.00      0.00         3\n",
            "    பேச்சு வழக்கு       0.66      0.49      0.56        77\n",
            "     பேச்சுவழக்கு       0.00      0.00      0.00         1\n",
            "        மகர ஈற்று       0.94      0.43      0.59        69\n",
            "      வினையாக்கம்       0.00      0.00      0.00         8\n",
            "      வினையெச்சம்       0.63      0.35      0.45        48\n",
            "     வேற்றெழுத்து       0.33      0.14      0.20        70\n",
            "\n",
            "         accuracy                           0.53      1005\n",
            "        macro avg       0.24      0.20      0.21      1005\n",
            "     weighted avg       0.52      0.53      0.50      1005\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  0   0   0   3   0   0   0   0   0   0   0   0   2   0   0   0   1   0\n",
            "    0   0   0   0]\n",
            " [  0  13   0   1   0   0   0   0   0  11   0   0   8   0   0   0   1   0\n",
            "    0   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  0   0   0  49   0   0   0   0   0  19   0   0   9   0   0   0   1   0\n",
            "    1   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
            "    0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   2   0   0   2   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   2   0\n",
            "    0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   5   1   0   0   2   0\n",
            "    0   0   2   0]\n",
            " [  0   4   0   6   0   0   0   0   0 172   0   0  48   3   0   0   1   0\n",
            "    0   0   4   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0   0   7   0   0   7   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  0   3   0  10   0   0   0   0   0  62   0   0 167   7   0   0   4   0\n",
            "    0   0   1   9]\n",
            " [  0   0   0   0   0   0   0   0   0   7   0   0  15  37   0   0   1   0\n",
            "    1   0   1   0]\n",
            " [  0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0   0\n",
            "    0   0   1   0]\n",
            " [  0   0   0   5   0   0   0   0   0   6   0   0  22   3   0   0  38   0\n",
            "    0   0   1   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
            "    0   0   0   0]\n",
            " [  0   0   0   4   0   0   0   0   0  18   0   0  13   3   0   0   0   0\n",
            "   30   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   5   0   0   0   1   0\n",
            "    0   0   0   1]\n",
            " [  0   2   0   1   0   0   0   0   0  12   0   0  13   0   0   0   2   0\n",
            "    0   0  17   1]\n",
            " [  0   1   0   2   0   0   0   0   0  26   0   0  27   2   0   0   2   0\n",
            "    0   0   0  10]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}