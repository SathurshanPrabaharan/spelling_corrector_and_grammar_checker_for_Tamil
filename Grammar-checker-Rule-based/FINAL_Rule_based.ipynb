{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e58bb7ec38e741bc96631d248f920819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af5d5aa924574488b60bed20712fce11",
              "IPY_MODEL_85c9c5aa46d541e099466d09c56cf716",
              "IPY_MODEL_95afca227b144bc08588a137a6f96a1d"
            ],
            "layout": "IPY_MODEL_05e481029ea04543aac257b5edcfc611"
          }
        },
        "af5d5aa924574488b60bed20712fce11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881cb6e0e72d4d1f88be9238070152b9",
            "placeholder": "​",
            "style": "IPY_MODEL_7367c0e6e22143fa8c671312b06c1f5e",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: "
          }
        },
        "85c9c5aa46d541e099466d09c56cf716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9d6bff646a4520b023b1f8339200a2",
            "max": 48453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_942b706afbd4428e87d60d209dd421e7",
            "value": 48453
          }
        },
        "95afca227b144bc08588a137a6f96a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2493236546174ab5afa4bf4bc990dba4",
            "placeholder": "​",
            "style": "IPY_MODEL_2ce68aeff73f4e1e9c81729eb794b3f8",
            "value": " 392k/? [00:00&lt;00:00, 13.8MB/s]"
          }
        },
        "05e481029ea04543aac257b5edcfc611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "881cb6e0e72d4d1f88be9238070152b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7367c0e6e22143fa8c671312b06c1f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b9d6bff646a4520b023b1f8339200a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942b706afbd4428e87d60d209dd421e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2493236546174ab5afa4bf4bc990dba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce68aeff73f4e1e9c81729eb794b3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "361ea04ed2d64c3d9693aede2c5f6516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bef53c330434ece97d0069062aae3d2",
              "IPY_MODEL_dc08ec34dd8d48889723ea394235a4f7",
              "IPY_MODEL_90cc0cd45e4b4ed6adf12213ee6f15a8"
            ],
            "layout": "IPY_MODEL_11d99548472a4ee8a75b2f8df3124429"
          }
        },
        "6bef53c330434ece97d0069062aae3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a43b9ba6aa0b4db9b7339a32bd31cd00",
            "placeholder": "​",
            "style": "IPY_MODEL_36a96fd4f0ed48b2a7d9775059f067ad",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: "
          }
        },
        "dc08ec34dd8d48889723ea394235a4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12f977985424aabbe31d3914015e7f1",
            "max": 48453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1294190f5e8a4568a9149e1ac9cfeac8",
            "value": 48453
          }
        },
        "90cc0cd45e4b4ed6adf12213ee6f15a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_164ed99115464fd095e3b2eef00a1b45",
            "placeholder": "​",
            "style": "IPY_MODEL_e1cb0407a5164ce1be46dfca2dc86f96",
            "value": " 392k/? [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "11d99548472a4ee8a75b2f8df3124429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43b9ba6aa0b4db9b7339a32bd31cd00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a96fd4f0ed48b2a7d9775059f067ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d12f977985424aabbe31d3914015e7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1294190f5e8a4568a9149e1ac9cfeac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "164ed99115464fd095e3b2eef00a1b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1cb0407a5164ce1be46dfca2dc86f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **EC9640 - Artificial Intelligence Project**\n",
        "### **Project Name** - Spelling corrector and grammar checker for Tamil\n",
        "### **Team Member** - 2020/E/067 & 2020/E/145"
      ],
      "metadata": {
        "id": "4B9jdqJF1Wdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rule Based  - Grammar Checker Implementation**"
      ],
      "metadata": {
        "id": "CTEnIYFp--F9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import nessary library"
      ],
      "metadata": {
        "id": "DQYQJryW07xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install stanza\n",
        "\n",
        "import stanza\n",
        "\n",
        "# Download Tamil model for Stanza\n",
        "stanza.download('ta')\n",
        "\n",
        "# Initialize the Stanza pipeline for Tamil\n",
        "nlp = stanza.Pipeline(lang='ta', processors='tokenize,pos,lemma,depparse')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e58bb7ec38e741bc96631d248f920819",
            "af5d5aa924574488b60bed20712fce11",
            "85c9c5aa46d541e099466d09c56cf716",
            "95afca227b144bc08588a137a6f96a1d",
            "05e481029ea04543aac257b5edcfc611",
            "881cb6e0e72d4d1f88be9238070152b9",
            "7367c0e6e22143fa8c671312b06c1f5e",
            "9b9d6bff646a4520b023b1f8339200a2",
            "942b706afbd4428e87d60d209dd421e7",
            "2493236546174ab5afa4bf4bc990dba4",
            "2ce68aeff73f4e1e9c81729eb794b3f8",
            "361ea04ed2d64c3d9693aede2c5f6516",
            "6bef53c330434ece97d0069062aae3d2",
            "dc08ec34dd8d48889723ea394235a4f7",
            "90cc0cd45e4b4ed6adf12213ee6f15a8",
            "11d99548472a4ee8a75b2f8df3124429",
            "a43b9ba6aa0b4db9b7339a32bd31cd00",
            "36a96fd4f0ed48b2a7d9775059f067ad",
            "d12f977985424aabbe31d3914015e7f1",
            "1294190f5e8a4568a9149e1ac9cfeac8",
            "164ed99115464fd095e3b2eef00a1b45",
            "e1cb0407a5164ce1be46dfca2dc86f96"
          ]
        },
        "id": "Iyg73DUQ_SSy",
        "outputId": "1e1ec6f6-d33f-4860-d933-0e6fc74a02b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stanza in /usr/local/lib/python3.10/dist-packages (1.9.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (4.25.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.67.1)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from stanza) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e58bb7ec38e741bc96631d248f920819"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Downloading default packages for language: ta (Tamil) ...\n",
            "INFO:stanza:File exists: /root/stanza_resources/ta/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n",
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "361ea04ed2d64c3d9693aede2c5f6516"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "WARNING:stanza:Language ta package default expects mwt, which has been added\n",
            "INFO:stanza:Loading these models for language: ta (Tamil):\n",
            "============================\n",
            "| Processor | Package      |\n",
            "----------------------------\n",
            "| tokenize  | ttb          |\n",
            "| mwt       | ttb          |\n",
            "| pos       | ttb_nocharlm |\n",
            "| lemma     | ttb_nocharlm |\n",
            "| depparse  | ttb_nocharlm |\n",
            "============================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: mwt\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/mwt/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: pos\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: lemma\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/lemma/trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: depparse\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/depparse/trainer.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Verbs Dictionary"
      ],
      "metadata": {
        "id": "dwwh_sFNZGvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tamil_dictionary_verbs = [\n",
        "    # Past Tense\n",
        "    \"படித்தேன்\", \"படித்தோம்\", \"படித்தாய்\", \"படித்தீர்கள்\", \"படித்தான்\", \"படித்தாள்\",\n",
        "    \"படித்தார்கள்\", \"படித்தது\", \"படித்தன\",\n",
        "\n",
        "    # Present Tense\n",
        "    \"படிக்கிறேன்\", \"படிக்கிறோம்\", \"படிக்கிறாய்\", \"படிக்கிறீர்கள்\", \"படிக்கிறான்\",\n",
        "    \"படிக்கிறாள்\", \"படிக்கிறார்கள்\", \"படிக்கிறது\", \"படிக்கின்றன\",\n",
        "\n",
        "    # Future Tense\n",
        "    \"படிப்பேன்\", \"படிப்போம்\", \"படிப்பாய்\", \"படிப்பீர்கள்\", \"படிப்பான்\", \"படிப்பாள்\",\n",
        "    \"படிப்பார்கள்\", \"படிக்கும்\",\n",
        "\n",
        "    # # Imperative Mood\n",
        "    # \"படி\", \"படிங்க\",\n",
        "\n",
        "    # # Negative Verbs\n",
        "    # \"படிக்கவில்லை\", \"படிக்கமாட்டேன்\",\n",
        "\n",
        "    # # Gerund and Other Forms\n",
        "    # \"படித்து\", \"படிக்க\", \"படித்தல்\"\n",
        "\n",
        "    # Past Tense\n",
        "    \"சென்றேன்\", \"சென்றோம்\", \"சென்றாய்\", \"சென்றீர்கள்\", \"சென்றான்\", \"சென்றாள்\",\n",
        "    \"சென்றார்கள்\", \"சென்றது\", \"சென்றன\",\n",
        "\n",
        "    # Present Tense\n",
        "    \"செல்கிறேன்\", \"செல்கிறோம்\", \"செல்கிறாய்\", \"செல்கிறீர்கள்\", \"செல்கிறான்\",\n",
        "    \"செல்கிறாள்\", \"செல்கிறார்கள்\", \"செல்கிறது\", \"செல்கின்றன\",\n",
        "\n",
        "    # Future Tense\n",
        "    \"செல்வேன்\", \"செல்வோம்\", \"செல்வாய்\", \"செல்வீர்கள்\", \"செல்வான்\", \"செல்வாள்\",\n",
        "    \"செல்வார்கள்\", \"செல்லும்\",\n",
        "\n",
        "    # # Imperative Mood\n",
        "    # \"செல்\", \"செல்லுங்கள்\",\n",
        "\n",
        "    # # Negative Verbs\n",
        "    # \"செல்லவில்லை\", \"செல்லமாட்டேன்\",\n",
        "\n",
        "    # # Gerund and Other Forms\n",
        "    # \"சென்று\", \"செல்ல\", \"சென்றல்\"\n",
        "\n",
        "    # Past Tense\n",
        "    \"செய்தேன்\", \"செய்தோம்\", \"செய்தாய்\", \"செய்தீர்கள்\", \"செய்தான்\", \"செய்தாள்\",\"செய்தார்\",\n",
        "    \"செய்தார்கள்\", \"செய்தது\", \"செய்தன\",\n",
        "\n",
        "    # Present Tense\n",
        "    \"செய்கிறேன்\", \"செய்கிறோம்\", \"செய்கிறாய்\", \"செய்கிறீர்கள்\", \"செய்கிறான்\", \"செய்கிறார்\",\n",
        "    \"செய்கிறாள்\", \"செய்கிறார்கள்\", \"செய்கிறது\", \"செய்கின்றன\",\n",
        "\n",
        "    # Future Tense\n",
        "    \"செய்வேன்\", \"செய்வோம்\", \"செய்வாய்\", \"செய்வீர்கள்\", \"செய்வான்\", \"செய்வாள்\", \"செய்வார்\",\n",
        "    \"செய்வார்கள்\", \"செய்யும்\",\n",
        "\n",
        "    # Imperative Mood\n",
        "    # \"செய்\", \"செய்யுங்கள்\",\n",
        "\n",
        "    # # Negative Verbs\n",
        "    # \"செய்யவில்லை\", \"செய்யமாட்டேன்\",\n",
        "\n",
        "    # # Gerund and Other Forms\n",
        "    # \"செய்து\", \"செய்ய\", \"செய்தல்\"\n",
        "\n",
        "\n",
        "    # Past Tense\n",
        "    \"இருந்தேன்\", \"இருந்தோம்\", \"இருந்தாய்\", \"இருந்தீர்கள்\", \"இருந்தான்\", \"இருந்தாள்\", \"இருந்தார்\",\n",
        "    \"இருந்தார்கள்\", \"இருந்தது\", \"இருந்தன\",\n",
        "\n",
        "    # Present Tense\n",
        "    \"இருக்கிறேன்\", \"இருக்கிறோம்\", \"இருக்கிறாய்\", \"இருக்கிறீர்கள்\", \"இருக்கிறான்\", \"இருக்கிறாள்\",\n",
        "    \"இருக்கிறார்\", \"இருக்கிறார்கள்\", \"இருக்கிறது\", \"இருக்கின்றன\",\n",
        "\n",
        "    # Future Tense\n",
        "    \"இருப்பேன்\", \"இருப்போம்\", \"இருப்பாய்\", \"இருப்பீர்கள்\", \"இருப்பான்\", \"இருப்பாள்\",\n",
        "    \"இருப்பார்\", \"இருப்பார்கள்\", \"இருக்கும்\",\n",
        "\n",
        "    # Imperative Mood\n",
        "    # \"இரு\", \"இருங்கள்\",\n",
        "\n",
        "    # Negative Verbs\n",
        "    # \"இருக்கவில்லை\", \"இருக்கமாட்டேன்\",\n",
        "\n",
        "    # Gerund and Other Forms\n",
        "    # \"இருந்து\", \"இருக்க\", \"இருத்தல்\"\n",
        "]\n",
        "\n",
        "print(tamil_dictionary_verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1VMJqPKVU7V",
        "outputId": "ba4fa497-ffca-4346-8007-d6479058bed4"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['படித்தேன்', 'படித்தோம்', 'படித்தாய்', 'படித்தீர்கள்', 'படித்தான்', 'படித்தாள்', 'படித்தார்கள்', 'படித்தது', 'படித்தன', 'படிக்கிறேன்', 'படிக்கிறோம்', 'படிக்கிறாய்', 'படிக்கிறீர்கள்', 'படிக்கிறான்', 'படிக்கிறாள்', 'படிக்கிறார்கள்', 'படிக்கிறது', 'படிக்கின்றன', 'படிப்பேன்', 'படிப்போம்', 'படிப்பாய்', 'படிப்பீர்கள்', 'படிப்பான்', 'படிப்பாள்', 'படிப்பார்கள்', 'படிக்கும்', 'சென்றேன்', 'சென்றோம்', 'சென்றாய்', 'சென்றீர்கள்', 'சென்றான்', 'சென்றாள்', 'சென்றார்கள்', 'சென்றது', 'சென்றன', 'செல்கிறேன்', 'செல்கிறோம்', 'செல்கிறாய்', 'செல்கிறீர்கள்', 'செல்கிறான்', 'செல்கிறாள்', 'செல்கிறார்கள்', 'செல்கிறது', 'செல்கின்றன', 'செல்வேன்', 'செல்வோம்', 'செல்வாய்', 'செல்வீர்கள்', 'செல்வான்', 'செல்வாள்', 'செல்வார்கள்', 'செல்லும்', 'செய்தேன்', 'செய்தோம்', 'செய்தாய்', 'செய்தீர்கள்', 'செய்தான்', 'செய்தாள்', 'செய்தார்', 'செய்தார்கள்', 'செய்தது', 'செய்தன', 'செய்கிறேன்', 'செய்கிறோம்', 'செய்கிறாய்', 'செய்கிறீர்கள்', 'செய்கிறான்', 'செய்கிறார்', 'செய்கிறாள்', 'செய்கிறார்கள்', 'செய்கிறது', 'செய்கின்றன', 'செய்வேன்', 'செய்வோம்', 'செய்வாய்', 'செய்வீர்கள்', 'செய்வான்', 'செய்வாள்', 'செய்வார்', 'செய்வார்கள்', 'செய்யும்', 'இருந்தேன்', 'இருந்தோம்', 'இருந்தாய்', 'இருந்தீர்கள்', 'இருந்தான்', 'இருந்தாள்', 'இருந்தார்', 'இருந்தார்கள்', 'இருந்தது', 'இருந்தன', 'இருக்கிறேன்', 'இருக்கிறோம்', 'இருக்கிறாய்', 'இருக்கிறீர்கள்', 'இருக்கிறான்', 'இருக்கிறாள்', 'இருக்கிறார்', 'இருக்கிறார்கள்', 'இருக்கிறது', 'இருக்கின்றன', 'இருப்பேன்', 'இருப்போம்', 'இருப்பாய்', 'இருப்பீர்கள்', 'இருப்பான்', 'இருப்பாள்', 'இருப்பார்', 'இருப்பார்கள்', 'இருக்கும்']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tense Related words to find the actual tense"
      ],
      "metadata": {
        "id": "44aAI0h535zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tense_related_words = {\n",
        "  \"past\": [\n",
        "      \"நேற்று\",\n",
        "      \"நேற்றைய\",\n",
        "      \"முந்தினம்\",\n",
        "      \"சில நாட்களுக்கு முன்\",\n",
        "      \"சில நாட்களுக்கு முன்பு\",\n",
        "      \"சில நேரத்திற்கு முன்\",\n",
        "      \"சில நேரத்திற்கு முன்பு\",\n",
        "      \"சில நேரங்களுக்கு முன்\",\n",
        "      \"சில நேரங்களுக்கு முன்பு\"\n",
        "    ],\n",
        "  \"present\": [\n",
        "      \"இன்று\",\n",
        "      \"இப்பொழுது\",\n",
        "      \"இவ்வேளை\",\n",
        "      \"இவ்வேளைக்கு\",\n",
        "      \"இவ்வேளையில்\",\n",
        "      \"இன்றைக்கு\",\n",
        "      \"தற்போது\",\n",
        "      \"தற்போதைய\"\n",
        "  ],\n",
        "  \"future\":  [\n",
        "      \"நாளை\",\n",
        "      \"நாளைக்கு\",\n",
        "      \"எதிர்காலம்\",\n",
        "      \"எதிர்வரும்\",\n",
        "      \"எதிர்காலத்தில்\",\n",
        "      \"பின்னர்\",\n",
        "      \"ஒருநாள்\",\n",
        "      \"பிறகு\",\n",
        "      \"அடுத்த\"\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "y6u9SqFc161h"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Possible tense ending words for all pronounns"
      ],
      "metadata": {
        "id": "Oqzy0k404FRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tense_ending_words = {\n",
        "    'past':{\n",
        "        'நான்'      : ['தேன்','றேன்','னேன்','டேன்'], # 'றேன்'\n",
        "        'நாம்'      : ['தோம்','றோம்','னோம்','டோம்'], # 'றோம்'\n",
        "        'நாங்கள்'  : ['தோம்','றோம்','னோம்','டோம்'], # 'றோம்'\n",
        "        'நீ'         : ['தாய்','றாய்','னாய்','டாய்'],\n",
        "        'நீங்கள்'    : ['தீர்கள்','றீர்கள்','னீர்கள்','டீர்கள்'], # 'றீர்கள்'\n",
        "        'அவன்'     : ['தான்','றான்','னான்','டான்'], #'றான்'\n",
        "        'அவள்'     : ['தாள்','றாள்','னாள்','டாள்'], # 'றாள்'\n",
        "        'அவர்கள்'  : ['தார்கள்','றார்கள்','னார்கள்','டனர்','டார்கள்'], #'றார்கள்'\n",
        "        'அவர்'      : ['தார்','றார்','னார்','டார்'],  # 'றார்'\n",
        "        'அது'      : ['தது','றது','யது','டது'], #'றது'\n",
        "        'அவை'    :['தன','றன','டின','டன'], #'றன'\n",
        "        'அவைகள்' :['தன','றன','டின','டன'] #'றன'\n",
        "    },\n",
        "    'present':{\n",
        "        'நான்': ['கிறேன்','கின்றேன்'], #'கிறேன்','கின்றேன்'\n",
        "        'நாம்': ['கிறோம்','கின்றோம்'], #'கிறோம்','கின்றோம்'\n",
        "        'நாங்கள்': ['கிறோம்','கின்றோம்'], #'கிறோம்','கின்றோம்'\n",
        "        'நீ':  ['கிறாய்','கின்றாய்'],\n",
        "        'நீங்கள்': ['கிறீர்கள்','கின்றீர்கள்'],\n",
        "        'அவன்': ['கிறான்','கின்றான்'],\n",
        "        'அவள்': ['கிறாள்','கின்றாள்'],\n",
        "        'அவர்கள்': ['கிறார்கள்','கின்றார்கள்'],\n",
        "        'அவர்': ['கிறார்','கின்றார்'],\n",
        "        'அது': ['கிறது','கின்றது'],\n",
        "        'அவை':['கிறன','கின்றன'],\n",
        "        'அவைகள்':['கிறன','கின்றன']\n",
        "    },\n",
        "    'future':{\n",
        "        'நான்': ['பேன்','வேன்'],\n",
        "        'நாம்': ['போம்','வோம்'],\n",
        "        'நாங்கள்': ['போம்','வோம்'],\n",
        "        'நீ': ['பாய்','வாய்'],\n",
        "        'நீங்கள்': ['பீர்கள்','வீர்கள்'],\n",
        "        'அவன்': ['பான்','வான்'],\n",
        "        'அவள்': ['பாள்','வாள்'],\n",
        "        'அவர்கள்': ['பார்கள்','வார்கள்'],\n",
        "        'அவர்': ['பார்','வார்'],\n",
        "        'அது': ['கும்','லும்'],\n",
        "        'அவை':['கும்','லும்'],\n",
        "        'அவைகள்':['கும்','லும்']\n",
        "    },\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "4WJRNrPylFp1"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List of all ending words for a verb"
      ],
      "metadata": {
        "id": "uIA-Kp9u4MIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract lists for each tense\n",
        "past_list = [item for sublist in tense_ending_words['past'].values() for item in sublist]\n",
        "present_list = [item for sublist in tense_ending_words['present'].values() for item in sublist]\n",
        "future_list = [item for sublist in tense_ending_words['future'].values() for item in sublist]\n",
        "all_verb_endings_words = present_list + past_list + future_list\n",
        "\n",
        "print(\"Past:\", past_list)\n",
        "print(\"Present:\", present_list)\n",
        "print(\"Future:\", future_list)\n",
        "print(\"All ending words:\", all_verb_endings_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7hxaHp_75Uq",
        "outputId": "d738ca2c-6dbd-43d0-a58f-55ed4f704879"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Past: ['தேன்', 'றேன்', 'னேன்', 'டேன்', 'தோம்', 'றோம்', 'னோம்', 'டோம்', 'தோம்', 'றோம்', 'னோம்', 'டோம்', 'தாய்', 'றாய்', 'னாய்', 'டாய்', 'தீர்கள்', 'றீர்கள்', 'னீர்கள்', 'டீர்கள்', 'தான்', 'றான்', 'னான்', 'டான்', 'தாள்', 'றாள்', 'னாள்', 'டாள்', 'தார்கள்', 'றார்கள்', 'னார்கள்', 'டனர்', 'டார்கள்', 'தார்', 'றார்', 'னார்', 'டார்', 'தது', 'றது', 'யது', 'டது', 'தன', 'றன', 'டின', 'டன', 'தன', 'றன', 'டின', 'டன']\n",
            "Present: ['கிறேன்', 'கின்றேன்', 'கிறோம்', 'கின்றோம்', 'கிறோம்', 'கின்றோம்', 'கிறாய்', 'கின்றாய்', 'கிறீர்கள்', 'கின்றீர்கள்', 'கிறான்', 'கின்றான்', 'கிறாள்', 'கின்றாள்', 'கிறார்கள்', 'கின்றார்கள்', 'கிறார்', 'கின்றார்', 'கிறது', 'கின்றது', 'கிறன', 'கின்றன', 'கிறன', 'கின்றன']\n",
            "Future: ['பேன்', 'வேன்', 'போம்', 'வோம்', 'போம்', 'வோம்', 'பாய்', 'வாய்', 'பீர்கள்', 'வீர்கள்', 'பான்', 'வான்', 'பாள்', 'வாள்', 'பார்கள்', 'வார்கள்', 'பார்', 'வார்', 'கும்', 'லும்', 'கும்', 'லும்', 'கும்', 'லும்']\n",
            "All ending words: ['கிறேன்', 'கின்றேன்', 'கிறோம்', 'கின்றோம்', 'கிறோம்', 'கின்றோம்', 'கிறாய்', 'கின்றாய்', 'கிறீர்கள்', 'கின்றீர்கள்', 'கிறான்', 'கின்றான்', 'கிறாள்', 'கின்றாள்', 'கிறார்கள்', 'கின்றார்கள்', 'கிறார்', 'கின்றார்', 'கிறது', 'கின்றது', 'கிறன', 'கின்றன', 'கிறன', 'கின்றன', 'தேன்', 'றேன்', 'னேன்', 'டேன்', 'தோம்', 'றோம்', 'னோம்', 'டோம்', 'தோம்', 'றோம்', 'னோம்', 'டோம்', 'தாய்', 'றாய்', 'னாய்', 'டாய்', 'தீர்கள்', 'றீர்கள்', 'னீர்கள்', 'டீர்கள்', 'தான்', 'றான்', 'னான்', 'டான்', 'தாள்', 'றாள்', 'னாள்', 'டாள்', 'தார்கள்', 'றார்கள்', 'னார்கள்', 'டனர்', 'டார்கள்', 'தார்', 'றார்', 'னார்', 'டார்', 'தது', 'றது', 'யது', 'டது', 'தன', 'றன', 'டின', 'டன', 'தன', 'றன', 'டின', 'டன', 'பேன்', 'வேன்', 'போம்', 'வோம்', 'போம்', 'வோம்', 'பாய்', 'வாய்', 'பீர்கள்', 'வீர்கள்', 'பான்', 'வான்', 'பாள்', 'வாள்', 'பார்கள்', 'வார்கள்', 'பார்', 'வார்', 'கும்', 'லும்', 'கும்', 'லும்', 'கும்', 'லும்']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the embedding model"
      ],
      "metadata": {
        "id": "XTTE9mw43iRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(\"/content/cc.ta.300.bin\"):\n",
        "  !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ta.300.bin.gz\n",
        "  !gunzip cc.ta.300.bin.gz"
      ],
      "metadata": {
        "id": "4l86VnXP1-3j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import fasttext\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load pre-trained binary FastText embeddings\n",
        "embedding_path = \"cc.ta.300.bin\"  # Path to pre-trained Tamil FastText embeddings\n",
        "model = fasttext.load_model(embedding_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV-2LNVXeD34",
        "outputId": "1226e825-becb-4860-bced-7e728717f5d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for find the pronoun for subject"
      ],
      "metadata": {
        "id": "A-TaF_PB3_j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_subject_pronoun(subject):\n",
        "  person = None\n",
        "  number = None\n",
        "  gender = None  # Add gender variable\n",
        "  subject_features = subject.feats or \"\"\n",
        "\n",
        "  # find the person\n",
        "  if \"Person=1\" in subject_features:\n",
        "      person = 1\n",
        "  elif \"Person=2\" in subject_features:\n",
        "      person = 2\n",
        "  elif \"Person=3\" in subject_features:\n",
        "    person = 3\n",
        "\n",
        "  # find the numbers\n",
        "  if \"Number=Sing\" in subject_features:\n",
        "      number = \"singular\"\n",
        "  elif \"Number=Plur\" in subject_features:\n",
        "      number = \"plural\"\n",
        "\n",
        "  # find the gender (if available)\n",
        "  if \"Gender=Masc\" in subject_features:\n",
        "      gender = \"masculine\"\n",
        "  elif \"Gender=Fem\" in subject_features:\n",
        "      gender = \"feminine\"\n",
        "  elif \"Gender=Neut\" in subject_features:  # Add neuter gender\n",
        "      gender = \"neuter\"\n",
        "  elif  \"Gender=Com\" in subject_features:  # Add common gender\n",
        "      gender = \"common\"\n",
        "\n",
        "  ########################################################\n",
        "  # Print details\n",
        "  # print('Person : ',person)\n",
        "  # print('Number : ',number)\n",
        "  # print('Gender : ',gender)\n",
        "  ########################################################\n",
        "\n",
        "  # Pronoun mapping based on person, number, and gender\n",
        "  pronoun_mapping = {\n",
        "      (1, \"singular\"): \"நான்\",\n",
        "      (1, \"plural\"): \"நாங்கள்\",\n",
        "      (2, \"singular\"): \"நீ\",\n",
        "      (2, \"plural\"): \"நீங்கள்\",\n",
        "      (3, \"singular\", \"masculine\"): \"அவன்\",\n",
        "      (3, \"singular\", \"feminine\"): \"அவள்\",\n",
        "      (3, \"singular\", \"common\"): \"அவர்\",\n",
        "      (3, \"singular\", \"neuter\"): \"அது\",  # Add neuter singular\n",
        "      (3, \"plural\"): \"அவர்கள்\",\n",
        "      (3, \"plural\", \"neuter\"): \"அவைகள்\" # Add neuter plural\n",
        "\n",
        "  }\n",
        "\n",
        "  pronoun = pronoun_mapping.get((person, number, gender), pronoun_mapping.get((person, number)))\n",
        "  # Try to get pronoun with gender, if not found, try without gender\n",
        "\n",
        "  return [pronoun, person,number,gender]"
      ],
      "metadata": {
        "id": "Gqwx8jK6pKlT"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for finding the tense of the verb"
      ],
      "metadata": {
        "id": "gh21GTwo4WSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def find_verb_tense(verb):\n",
        "  tense = None\n",
        "  tense_pos = None\n",
        "  tense_ends = None\n",
        "\n",
        "  # find the tense using verb features\n",
        "  verb_features = verb.feats or \"\"\n",
        "  if \"Tense\" in verb_features:\n",
        "    if \"Tense=Pres\" in verb_features:\n",
        "      tense_pos = \"present\"\n",
        "    elif \"Tense=Past\" in verb_features:\n",
        "        tense_pos = \"past\"\n",
        "    elif \"Tense=Fut\" in verb_features:\n",
        "        tense_pos = \"future\"\n",
        "\n",
        "  # find tense using ending words\n",
        "  if any(verb.text.endswith(suffix) for suffix in present_list):\n",
        "      tense_ends = \"present\"\n",
        "  elif any(verb.text.endswith(suffix) for suffix in past_list):\n",
        "      tense_ends = \"past\"\n",
        "  elif any(verb.text.endswith(suffix) for suffix in future_list):\n",
        "      tense_ends = \"future\"\n",
        "\n",
        "\n",
        "\n",
        "  # Finalize the tense\n",
        "  if tense_pos and tense_ends:\n",
        "    if tense_pos == tense_ends:\n",
        "      tense = tense_pos\n",
        "    else:\n",
        "      tense = tense_ends\n",
        "  elif tense_pos:\n",
        "    tense = tense_pos\n",
        "  elif tense_ends:\n",
        "    tense = tense_ends\n",
        "  else:\n",
        "    print('tense not found.............')\n",
        "    # tense = random.choice([\"past\", \"present\", \"future\"])\n",
        "    tense = \"Unknown\"\n",
        "  #############################\n",
        "  # print('tense_pos : ',tense_pos)\n",
        "  # print('tense_ends : ',tense_ends)\n",
        "  # print('verb_tense : ',tense)\n",
        "  #############################\n",
        "\n",
        "  return tense"
      ],
      "metadata": {
        "id": "Zb24nE72yRFg"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for generating possible verb using suffix"
      ],
      "metadata": {
        "id": "xR_JPCEb4ee9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the consonant from a letter\n",
        "def get_consonant(letter):\n",
        "    # Check if the letter ends with a pulli (்), return the consonant part\n",
        "    if letter[-1] == '்':  # Pulli mark\n",
        "        return letter\n",
        "    return letter  # If no pulli, return as is\n",
        "\n",
        "# Function to correct the word and generate all possible corrected verbs\n",
        "def generate_possible_verbs(verb, wrong_suffix, possible_suffixes,actual_tense,verb_tense):\n",
        "    possible_verbs = []\n",
        "    word = verb.text\n",
        "    lemma = verb.lemma\n",
        "    diff_base_verb = None\n",
        "    current_base_verb = None\n",
        "    if lemma in base_verbs.keys():\n",
        "      diff_base_verb = base_verbs[lemma][actual_tense]\n",
        "      current_base_verb = base_verbs[lemma][verb_tense]\n",
        "      # print('diff_base_verb : ',diff_base_verb)\n",
        "      # print('current_base_verb : ',current_base_verb)\n",
        "\n",
        "    if diff_base_verb and diff_base_verb != lemma:\n",
        "      lemmas = [diff_base_verb, lemma]\n",
        "    else:\n",
        "      lemmas = [lemma]\n",
        "\n",
        "    # print('lemmas : ',lemmas)\n",
        "\n",
        "    for verb_lemma in lemmas:\n",
        "       if word.endswith(wrong_suffix):\n",
        "          # Remove the incorrect suffix to get the base word\n",
        "          base_word = word[:-len(wrong_suffix)]\n",
        "\n",
        "          # Extract the last consonant from the base word\n",
        "          last_consonant_base = get_consonant(base_word[-1])\n",
        "\n",
        "          # print('verb_lemma : ', verb_lemma)\n",
        "          # print('base_word : ', base_word)\n",
        "          # print('last_consonant_base : ', last_consonant_base)\n",
        "\n",
        "          # check whether base_word and verb_lemma are not same\n",
        "          if base_word != verb_lemma and len(base_word) != len(verb_lemma) :\n",
        "            # Check if last consonant is ்\n",
        "            if last_consonant_base == '்':\n",
        "                # Remove the last two letters from the base word\n",
        "                base_word = base_word[:-1]  # Remove pulli mark\n",
        "                base_word = base_word[:-1]  # Remove the last consonant\n",
        "\n",
        "                # print('Updated base_word after removing last two letters: ', base_word)\n",
        "\n",
        "                # Generate all possible corrected verbs with pulli\n",
        "                for suffix in possible_suffixes:\n",
        "                    first_consonant_suffix = get_consonant(suffix[0])\n",
        "                    corrected_verb = base_word + first_consonant_suffix + '்' + suffix\n",
        "                    possible_verbs.append(corrected_verb)\n",
        "                # Generate all possible corrected verbs without pulli\n",
        "                for suffix in possible_suffixes:\n",
        "                    first_consonant_suffix = get_consonant(suffix[0])\n",
        "                    corrected_verb = base_word + suffix\n",
        "                    possible_verbs.append(corrected_verb)\n",
        "\n",
        "          else:\n",
        "            if current_base_verb:\n",
        "              base_word = base_word.replace(current_base_verb,verb_lemma )\n",
        "            else:\n",
        "              base_word = base_word.replace(verb_lemma,verb_lemma )\n",
        "            # Generate all possible corrected verbs with pulli\n",
        "            for suffix in possible_suffixes:\n",
        "                first_consonant_suffix = get_consonant(suffix[0])\n",
        "                corrected_verb = base_word + first_consonant_suffix + '்' + suffix\n",
        "                possible_verbs.append(corrected_verb)\n",
        "            # Generate all possible corrected verbs without pulli\n",
        "            for suffix in possible_suffixes:\n",
        "                first_consonant_suffix = get_consonant(suffix[0])\n",
        "                corrected_verb = base_word + suffix\n",
        "                possible_verbs.append(corrected_verb)\n",
        "\n",
        "\n",
        "    return possible_verbs\n",
        "\n"
      ],
      "metadata": {
        "id": "anWy799EScyz"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base verb vary with tenses"
      ],
      "metadata": {
        "id": "mhIFg_y5Pf7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_verbs = {\n",
        "    'செல்': {\n",
        "        'past':'சென்',\n",
        "        'present':'செல்',\n",
        "        'future': 'சென்'\n",
        "    },\n",
        "    'ஓடு': {\n",
        "        'past':'ஓடி',\n",
        "        'present':'ஓடு',\n",
        "        'future': 'ஓடு'\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "PgjxzEYhPeYL"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for find the most suitable verb from possible verbs"
      ],
      "metadata": {
        "id": "UyiDi7_Q3uYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 1 : words in model"
      ],
      "metadata": {
        "id": "_dsSbvJzch_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# Function to find the most suitable word\n",
        "def find_most_suitable_word_for_all_1(inputs, dictionary, model):\n",
        "    ##################################\n",
        "    # print('inputs : ',inputs)\n",
        "    # print('dictionary : ',dictionary)\n",
        "    # print('model : ',model)\n",
        "    ##################################\n",
        "    # Calculate the average embedding for all input words\n",
        "    input_vectors = []\n",
        "    for word in inputs:\n",
        "        # print('word in input : ',word)\n",
        "        if word in model:  # Skip words not in the model\n",
        "            # print('word in model : ',word)\n",
        "            input_vectors.append(model.get_word_vector(word))\n",
        "    if not input_vectors:\n",
        "        return None  # No valid embeddings for inputs\n",
        "    average_input_vector = np.mean(input_vectors, axis=0)\n",
        "\n",
        "    # Find the dictionary word with the highest similarity to the average embedding\n",
        "    best_match = None\n",
        "    highest_similarity = -1\n",
        "\n",
        "    # print('dictionary : ',dictionary)\n",
        "\n",
        "    for dict_word in dictionary:\n",
        "        # print(\"dict_word: \",dict_word)\n",
        "        dict_vector = model.get_word_vector(dict_word)\n",
        "        similarity = cosine_similarity([average_input_vector], [dict_vector])[0][0]\n",
        "        # print('similarity : ',similarity)\n",
        "        if similarity > highest_similarity:\n",
        "            highest_similarity = similarity\n",
        "            best_match = dict_word\n",
        "\n",
        "    return best_match\n",
        "\n",
        "# verbs = ['செய்த்தார்', 'செய்ற்றார்', 'செய்ன்னார்', 'செய்ட்டார்']\n",
        "# test = find_most_suitable_word_for_all(verbs, tamil_dictionary_verbs, model)\n",
        "# print('correct verb : ',test)"
      ],
      "metadata": {
        "id": "VPXECUoKdzFp"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2 : words not in the model"
      ],
      "metadata": {
        "id": "nkaUw6K7ckh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to find the most suitable word from the dictionary\n",
        "def find_most_suitable_word_for_all_2(inputs, dictionary, model):\n",
        "    # Generate embeddings for inputs\n",
        "    input_vectors = []\n",
        "    for word in inputs:\n",
        "        # print(f\"Generating embedding for: {word}\")\n",
        "        input_vectors.append(model.get_word_vector(word))  # Generate embedding even for OOV words\n",
        "\n",
        "    # Compute the average embedding of input words\n",
        "    average_input_vector = np.mean(input_vectors, axis=0)\n",
        "\n",
        "    # Precompute embeddings for the dictionary\n",
        "    dictionary_embeddings = {}\n",
        "    for dict_word in dictionary:\n",
        "        # print(f\"Generating embedding for dictionary word: {dict_word}\")\n",
        "        dictionary_embeddings[dict_word] = model.get_word_vector(dict_word)\n",
        "\n",
        "    # Find the dictionary word with the highest similarity\n",
        "    best_match = None\n",
        "    highest_similarity = -1\n",
        "    for dict_word, dict_vector in dictionary_embeddings.items():\n",
        "        similarity = cosine_similarity([average_input_vector], [dict_vector])[0][0]\n",
        "        # print(f\"Similarity between input and '{dict_word}': {similarity}\")\n",
        "        if similarity > highest_similarity:\n",
        "            highest_similarity = similarity\n",
        "            best_match = dict_word\n",
        "\n",
        "    return best_match\n",
        "\n",
        "# # Example inputs and dictionary\n",
        "# verbs = ['செய்த்தார்', 'செய்ற்றார்', 'செய்ன்னார்', 'செய்ட்டார்']  # Generated verbs\n",
        "# # tamil_dictionary_verbs = [\"செய்தான்\", \"செய்கிறான்\", \"செய்வான்\", \"செய்யும்\"]  # Prepared dictionary verbs\n",
        "\n",
        "\n",
        "# # Find the most suitable verb\n",
        "# correct_verb = find_most_suitable_word_for_all(verbs, tamil_dictionary_verbs, model)\n",
        "# print(\"Correct Verb:\", correct_verb)\n"
      ],
      "metadata": {
        "id": "us-Haq0yCSwV"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grammar checker Implementation"
      ],
      "metadata": {
        "id": "IJyq91mE4ox6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grammar_checker(sentence_data):\n",
        "    \"\"\"\n",
        "    Check and correct grammar errors.\n",
        "    \"\"\"\n",
        "    corrections = []\n",
        "    subject_pronoun = []\n",
        "    subject_noun = []\n",
        "    subject = None\n",
        "    verb = None\n",
        "    adverb = None\n",
        "    actual_tense = None\n",
        "    verb_tense = None\n",
        "    number = None\n",
        "    gender = None\n",
        "    pronoun = None\n",
        "\n",
        "\n",
        "    # Identify subject, verb and adverb\n",
        "    for word in sentence_data.words:\n",
        "        if word.deprel == \"nsubj\" and word.upos == \"PRON\":  # Prioritize pronoun as the subject\n",
        "            subject_pronoun.append(word)\n",
        "        elif word.deprel == \"nsubj\" and word.upos == \"NOUN\":\n",
        "            subject_noun.append(word)\n",
        "        elif word.deprel == \"root\" and word.upos == \"VERB\":  # Root verb\n",
        "            verb = word\n",
        "        if word.upos == \"ADV\":  # Adverb\n",
        "            adverb = word\n",
        "\n",
        "    # handle if both noun and pronoun are found as subject\n",
        "    if subject_pronoun and subject_noun:\n",
        "        subject = subject_pronoun[0]\n",
        "    elif subject_pronoun:\n",
        "        subject = subject_pronoun[0]\n",
        "    elif subject_noun:\n",
        "        subject = subject_noun[0]\n",
        "    else:\n",
        "        subject = [word for word in sentence_data.words if word.upos in (\"NOUN\", \"PRON\",\"PROPN\")]\n",
        "        subject=subject[0]\n",
        "\n",
        "    #################################\n",
        "    if subject:\n",
        "      # print('subject: ',subject.text)\n",
        "      pronoun, person,number,gender = find_subject_pronoun(subject)\n",
        "      # print('pronoun : ',pronoun)\n",
        "    # if verb: print('verb: ',verb.text)\n",
        "    # print('verb: ',verb.text) if verb else print('No verb')\n",
        "    # print('adverb: ',adverb.text) if adverb else print('No adverb')\n",
        "    #################################\n",
        "\n",
        "\n",
        "\n",
        "    # find the verb tense\n",
        "    if verb:\n",
        "      verb_tense = find_verb_tense(verb)\n",
        "\n",
        "\n",
        "    # find the actual tense\n",
        "    if adverb:\n",
        "      if adverb and adverb.lemma in tense_related_words[\"past\"]:\n",
        "        actual_tense = \"past\"\n",
        "      elif adverb and adverb.lemma in tense_related_words[\"present\"]:\n",
        "        actual_tense = \"present\"\n",
        "      elif adverb and adverb.lemma in tense_related_words[\"future\"]:\n",
        "        actual_tense = \"future\"\n",
        "      else:\n",
        "        actual_tense = verb_tense\n",
        "    else:\n",
        "        actual_tense = verb_tense\n",
        "\n",
        "    # print('actual_tense : ',actual_tense)\n",
        "\n",
        "    # Check the tense error and display it\n",
        "    is_tense_error = False\n",
        "    if(actual_tense != verb_tense):\n",
        "      is_tense_error = True\n",
        "      print(f'\\nTENSE ERROR :\\nThe sentence should be in {actual_tense} but the verb tense is {verb_tense}')\n",
        "\n",
        "    # check Subject-Verb Agreement error and display it\n",
        "    is_subject_Verb_Agreement_error = None\n",
        "    if subject and verb:\n",
        "      endind_words = tense_ending_words[verb_tense][pronoun]\n",
        "      ##############################################\n",
        "      # print(f'\\nchecking ending words...............')\n",
        "      # print(f'Ending words for {pronoun} are: {endind_words}')\n",
        "      ##############################################\n",
        "      is_subject_Verb_Agreement_error = True\n",
        "      for ending_word in endind_words:\n",
        "        # print('ending word : ',ending_word)\n",
        "        if verb.text.endswith(ending_word):\n",
        "          # print(f'*************ENDING WORD MATCH: {ending_word}************')\n",
        "          is_subject_Verb_Agreement_error = False\n",
        "          break\n",
        "      if is_subject_Verb_Agreement_error:\n",
        "        print(f'\\nSUBJECT VERB AGREEMENT ERROR:\\n{subject.text} should not be ended with {verb.text}')\n",
        "\n",
        "\n",
        "    # Correct the error\n",
        "\n",
        "    # find the wrong_suffix\n",
        "    if is_tense_error or is_subject_Verb_Agreement_error:\n",
        "      wrong_suffix = None\n",
        "      for ending_word in all_verb_endings_words:\n",
        "        if verb.text.endswith(ending_word):\n",
        "          wrong_suffix = ending_word\n",
        "          break\n",
        "      ##################################\n",
        "      # print('\\nwrong_suffix: ',wrong_suffix)\n",
        "      ##################################\n",
        "\n",
        "      verb_combinations = []\n",
        "      possible_suffixes = tense_ending_words[actual_tense][pronoun]\n",
        "\n",
        "\n",
        "      # if both error occur\n",
        "      # if is_tense_error and is_subject_Verb_Agreement_error or is_subject_Verb_Agreement_error:\n",
        "\n",
        "      # if there any error\n",
        "      if is_tense_error or is_subject_Verb_Agreement_error:\n",
        "        verb_combinations = generate_possible_verbs(verb, wrong_suffix, possible_suffixes,actual_tense,verb_tense)\n",
        "        # Find the most suitable word from all inputs\n",
        "        correct_verb = None\n",
        "        correct_verb = find_most_suitable_word_for_all_1(verb_combinations, tamil_dictionary_verbs, model)\n",
        "        if correct_verb is None:\n",
        "          correct_verb = find_most_suitable_word_for_all_2(verb_combinations, tamil_dictionary_verbs, model)\n",
        "        ###############################################\n",
        "        # print('possible_suffixes: ',possible_suffixes)\n",
        "        # print('verb_combinations: ',verb_combinations)\n",
        "        # print('correct_verb: ',correct_verb)\n",
        "        ###############################################\n",
        "        # Correctly join tokens without spaces before punctuation\n",
        "        original_sentence = \"\".join([\n",
        "            token.text if token.text in \".,!?;:\\\"\" else f\" {token.text}\"\n",
        "            for token in sentence_data.tokens\n",
        "        ]).strip()\n",
        "\n",
        "        corrcted_sentence = original_sentence.replace(verb.text, correct_verb)\n",
        "\n",
        "        # print(f'\\nOriginal sentence: {original_sentence}')\n",
        "        # print(f'Grammar suggestion: {corrcted_sentence}')\n",
        "\n",
        "        return corrcted_sentence\n",
        "\n",
        "      # if subject verb aggreement error occur\n",
        "      # elif is_subject_Verb_Agreement_error:\n",
        "    else:\n",
        "      original_sentence = \"\".join([\n",
        "            token.text+\" \" if token.text in \".,!?;:\\\"\" else f\" {token.text}\"\n",
        "            for token in sentence_data.tokens\n",
        "        ]).strip()\n",
        "      print(f'\\nNo error in the sentence: {original_sentence}')\n",
        "\n",
        "      return original_sentence\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZF2cpipwX30J"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Grammar Checker\n",
        "def check_grammar(original_para):\n",
        "    \"\"\"\n",
        "    Check and correct grammatical errors in a Tamil sentence.\n",
        "    \"\"\"\n",
        "    print(f\"\\nOriginal para: \\n{original_para}\")\n",
        "\n",
        "    doc = nlp(original_para)\n",
        "    corrected_para = \"\"\n",
        "    # sentence_count = 1\n",
        "\n",
        "    for sentence_data in doc.sentences:\n",
        "        # print(f\"\\nSentence {sentence_count}:\")\n",
        "        # sentence_count += 1\n",
        "        corrected_para = corrected_para + grammar_checker(sentence_data)\n",
        "\n",
        "\n",
        "    print(f\"\\ncorrected para: \\n{corrected_para}\")\n",
        "\n",
        "    # return corrected_para\n",
        "\n"
      ],
      "metadata": {
        "id": "u5JBq-2BgAgf"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Grammer checker"
      ],
      "metadata": {
        "id": "MQB385iIg4Iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define test paras"
      ],
      "metadata": {
        "id": "ic1bdnAxx2a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "para1 = \"நான் இன்று காலை பள்ளிக்குச் சென்றேன். நான் நேற்று மாலை சந்தைக்கு சென்றோம்.\"\n",
        "para2 = \"நீங்கள் நேற்று வேலை செய்தான். நான் நேற்று என் புத்தகம் படிக்கிறேன்.\"\n",
        "para3 = \"அவள் காலை உணவுகளை சமைக்கவில்லை. அவர் தன் வேலை செய்வான்.\"\n",
        "para4 = \"நாம் பாட்டு பாடுவார்கள். அவை மிகுந்த மகிழ்ச்சியாக இருந்தது.\"\n",
        "para5 = \"அவர்கள் இன்று படித்தான். நான் நேற்று காலையில் படிப்போம்.\"\n"
      ],
      "metadata": {
        "id": "2CCJkobAg7s_"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Para 01"
      ],
      "metadata": {
        "id": "tD8JZbZWx59s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_grammar(para1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1EewMuRx8BS",
        "outputId": "00b00d1f-bbd3-4a0c-cd87-8eb601186b60"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original para: \n",
            "நான் இன்று காலை பள்ளிக்குச் சென்றேன். நான் நேற்று மாலை சந்தைக்கு சென்றோம்.\n",
            "\n",
            "TENSE ERROR :\n",
            "The sentence should be in present but the verb tense is past\n",
            "\n",
            "SUBJECT VERB AGREEMENT ERROR:\n",
            "நான் should not be ended with சென்றோம்\n",
            "\n",
            "corrected para: \n",
            "நான் இன்று காலை பள்ளிக்குச் செல்கிறேன்.நான் நேற்று மாலை சந்தைக்கு சென்றேன்.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Para 02"
      ],
      "metadata": {
        "id": "XjI9rm-rzQ0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_grammar(para2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyZanAf3ympO",
        "outputId": "0baea01a-cb58-418b-f239-8198a676794e"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original para: \n",
            "நீங்கள் நேற்று வேலை செய்தான். நான் நேற்று என் புத்தகம் படிக்கிறேன்.\n",
            "\n",
            "SUBJECT VERB AGREEMENT ERROR:\n",
            "நீங்கள் should not be ended with செய்தான்\n",
            "\n",
            "TENSE ERROR :\n",
            "The sentence should be in past but the verb tense is present\n",
            "\n",
            "corrected para: \n",
            "நீங்கள் நேற்று வேலை செய்தீர்கள்.நான் நேற்று என் புத்தகம் படித்தேன்.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Para 03"
      ],
      "metadata": {
        "id": "7cjSJgRFzSOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_grammar(para3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctG5BRG-zSsY",
        "outputId": "1442ac94-9242-4741-ebf1-089d4df63952"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original para: \n",
            "அவள் காலை உணவுகளை சமைக்கவில்லை. அவர் தன் வேலை செய்வான்.\n",
            "\n",
            "No error in the sentence: அவள் காலை உணவுகளை சமைக்கவில்லை.\n",
            "\n",
            "SUBJECT VERB AGREEMENT ERROR:\n",
            "அவர் should not be ended with செய்வான்\n",
            "\n",
            "corrected para: \n",
            "அவள் காலை உணவுகளை சமைக்கவில்லை.அவர் தன் வேலை செய்வார்.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Para 04"
      ],
      "metadata": {
        "id": "4zrHWTqzzTS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_grammar(para4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOeP_WhOzT5i",
        "outputId": "aa2e57e5-5234-4321-8c2a-786cb6a3fd17"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original para: \n",
            "நாம் பாட்டு பாடுவார்கள். அவை மிகுந்த மகிழ்ச்சியாக இருந்தது.\n",
            "\n",
            "SUBJECT VERB AGREEMENT ERROR:\n",
            "நாம் should not be ended with பாடுவார்கள்\n",
            "\n",
            "SUBJECT VERB AGREEMENT ERROR:\n",
            "அவை should not be ended with இருந்தது\n",
            "\n",
            "corrected para: \n",
            "நாம் பாட்டு படிப்போம்.அவை மிகுந்த மகிழ்ச்சியாக இருந்தன.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Para 05"
      ],
      "metadata": {
        "id": "xCQn50A7zUj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_grammar(para5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yesXEr--zVF9",
        "outputId": "9b32c3ec-3ce2-4733-a113-50694f3e6638"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original para: \n",
            "அவர்கள் இன்று படித்தான். நான் நேற்று காலையில் படிப்போம்.\n",
            "\n",
            "TENSE ERROR :\n",
            "The sentence should be in present but the verb tense is past\n",
            "\n",
            "SUBJECT VERB AGREEMENT ERROR:\n",
            "அவர்கள் should not be ended with படித்தான்\n",
            "\n",
            "TENSE ERROR :\n",
            "The sentence should be in past but the verb tense is future\n",
            "\n",
            "SUBJECT VERB AGREEMENT ERROR:\n",
            "நான் should not be ended with படிப்போம்\n",
            "\n",
            "corrected para: \n",
            "அவர்கள் இன்று படிக்கிறார்கள்.நான் நேற்று காலையில் படித்தேன்.\n"
          ]
        }
      ]
    }
  ]
}