{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNAwdksCIA3N",
        "outputId": "38650046-6cfc-4d9e-f807-21f4cd88c495"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fasttext\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_0lEUsKjt9p",
        "outputId": "b67f442f-1672-45b4-cee4-82e169208d64"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296187 sha256=cfb38af5ea49104a6844772e9078253ad8ca921c084123bb1b8838dbb62c037f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip cc.ta.300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrFOVsBGlWMp",
        "outputId": "843549de-cb3d-4337-a098-65bba257c5a5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: cc.ta.300.bin.gz: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from difflib import get_close_matches\n",
        "from collections import defaultdict\n",
        "\n",
        "# Function to load words from multiple .txt files\n",
        "def load_words_from_files(file_paths):\n",
        "    words = set()\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    words.add(line.strip().replace(\" \", \"\"))  # Add cleaned words\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File {file_path} not found.\")\n",
        "    return words\n",
        "\n",
        "# Function to generate n-grams from a word\n",
        "def generate_ngrams(word, n=2):\n",
        "    return [word[i:i+n] for i in range(len(word)-n+1)]\n",
        "\n",
        "# Function to suggest corrections based on fuzzy matching and n-grams\n",
        "def suggest_correction(word, word_list, ngram_dict, n=2):\n",
        "    # Fuzzy matching: Get the closest matches for the word from the word list\n",
        "    fuzzy_matches = get_close_matches(word, word_list, n=3, cutoff=0.7)  # Higher cutoff for relevant matches\n",
        "\n",
        "    # If no fuzzy matches, use n-gram-based suggestions\n",
        "    if not fuzzy_matches:\n",
        "        word_ngrams = generate_ngrams(word, n)\n",
        "        best_matches = defaultdict(int)\n",
        "        for ngram in word_ngrams:\n",
        "            for w in word_list:\n",
        "                if ngram in generate_ngrams(w, n):\n",
        "                    best_matches[w] += 1\n",
        "\n",
        "        # Sort matches by count (the more n-grams match, the higher the score)\n",
        "        best_matches = sorted(best_matches.items(), key=lambda x: x[1], reverse=True)\n",
        "        fuzzy_matches = [match[0] for match in best_matches[:3]]\n",
        "\n",
        "    return fuzzy_matches\n",
        "\n",
        "# Function to process sentences/paragraphs\n",
        "def check_paragraph_spelling(paragraph, word_list, ngram_dict):\n",
        "    # Split the paragraph into words using spaces and Tamil punctuation\n",
        "    words = re.findall(r'[\\u0B80-\\u0BFF]+', paragraph)\n",
        "\n",
        "    word_suggestions = []\n",
        "    for word in words:\n",
        "        if word in word_list:\n",
        "            word_suggestions.append((word, \"Correct\"))  # Exact match, no suggestion\n",
        "        else:\n",
        "            corrections = suggest_correction(word, word_list, ngram_dict)\n",
        "            if corrections:\n",
        "                word_suggestions.append((word, f\"Suggested : {', '.join(corrections)}\"))\n",
        "            else:\n",
        "                word_suggestions.append((word, \"No suggestions available\"))\n",
        "\n",
        "    return word_suggestions\n",
        "\n",
        "# Step 1: Define the paths of the .txt files you want to load\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/AI/paragraph.txt',\n",
        "    '/content/drive/MyDrive/AI/all-tamil-nouns.txt',\n",
        "    '/content/drive/MyDrive/AI/noun.txt',\n",
        "    '/content/drive/MyDrive/AI/verb1.txt',\n",
        "    '/content/drive/MyDrive/AI/verb2.txt',\n",
        "    '/content/drive/MyDrive/AI/numbers.txt',\n",
        "]\n",
        "\n",
        "# Step 2: Load the dictionary from all specified .txt files\n",
        "word_list = load_words_from_files(file_paths)\n",
        "\n",
        "# Step 3: Generate n-grams for the word list\n",
        "ngram_dict = {}\n",
        "for word in word_list:\n",
        "    ngram_dict[word] = generate_ngrams(word)\n",
        "\n",
        "# Step 4: Get input from the user\n",
        "paragraph_to_check = input(\"Enter a paragraph in Tamil: \")\n",
        "\n",
        "# Step 5: Check spelling for the entire paragraph\n",
        "word_suggestions = check_paragraph_spelling(paragraph_to_check, word_list, ngram_dict)\n",
        "\n",
        "# Step 6: Display individual word suggestions\n",
        "print(\"\\nDetailed Spell Check Results:\")\n",
        "for word, suggestion in word_suggestions:\n",
        "    print(f\"'{word}' : {suggestion}\")\n",
        "\n",
        "# Step 7: Auto-corrected paragraph based on suggestions\n",
        "auto_corrected_paragraph = paragraph_to_check\n",
        "for word, suggestion in word_suggestions:\n",
        "    if \"Suggested\" in suggestion:\n",
        "        correct_word = suggestion.split(':')[1].split(',')[0].strip()  # Choose the first suggestion\n",
        "        auto_corrected_paragraph = auto_corrected_paragraph.replace(word, correct_word)\n",
        "\n",
        "print(\"\\nAuto-corrected Paragraph:\")\n",
        "print(auto_corrected_paragraph)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZD1_tiKSBTw",
        "outputId": "1c3a8923-9af1-471c-a22a-05c22a637168"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a paragraph in Tamil: வணக்கம, எப்படீ இருக்கீங்க? நான் உங்களை நேசிகிறேன். இந்த சூரியன் காலைல எழும்புகும் போது அதை பாத்து எனக்கு ரொம்ப சந்தோஷம் ஆகிறது. நமக்கும் பயபட்டேண்டா தேவை.\n",
            "\n",
            "Detailed Spell Check Results:\n",
            "'வணக்கம' : Suggested : வணக்கம், வணக்கு, ஆவணக்களம்\n",
            "'எப்படீ' : Suggested : எப்படி\n",
            "'இருக்கீங்க' : Correct\n",
            "'நான்' : Correct\n",
            "'உங்களை' : Correct\n",
            "'நேசிகிறேன்' : Suggested : நேசிக்கிறேன், நேசகன், தேசிகன்\n",
            "'இந்த' : Correct\n",
            "'சூரியன்' : Correct\n",
            "'காலைல' : Suggested : காலை, காமலை, கசாலை\n",
            "'எழும்புகும்' : Suggested : எழும்பும், எம்புகம், அழுப்புகம்\n",
            "'போது' : Correct\n",
            "'அதை' : Correct\n",
            "'பாத்து' : Correct\n",
            "'எனக்கு' : Correct\n",
            "'ரொம்ப' : Correct\n",
            "'சந்தோஷம்' : Correct\n",
            "'ஆகிறது' : Correct\n",
            "'நமக்கும்' : Correct\n",
            "'பயபட்டேண்டா' : Suggested : ,உண்ணவேண்டிவருகிறோம்,காணவேண்டிவருகிறோம்,கேட்கவேண்டிவருகிறோம்,கொடுக்கவேண்டிவருகிறோம்,செய்யவேண்டிவருகிறோம்,அழவேண்டிவருகிறோம்,சாகவேண்டிவருகிறோம்,தின்கவேண்டிவருகிறோம்,நிற்கவேண்டிவருகிறோம்,கற்கவேண்டிவருகிறோம்,செல்லவேண்டிவருகிறோம்,பெறவேண்டிவருகிறோம்,ஓடவேண்டிவருகிறோம்,சொல்லவேண்டிவருகிறோம்,போகவேண்டிவருகிறோம்,ஆகவேண்டிவருகிறோம்,நடக்கவேண்டிவருகிறோம்,எழவேண்டிவருகிறோம்,வளரவேண்டிவருகிறோம்,அலையவேண்டிவருகிறோம்,வரமாட்டாள்,ஆளவேண்டிவருகிறோம்,விடவேண்டிவருகிறோம்,கொள்ளவேண்டிவருகிறோம்,பயிலவேண்டிவருகிறோம், ,உண்ணவேண்டிவருகிறீர்,காணவேண்டிவருகிறீர்,கேட்கவேண்டிவருகிறீர்,கொடுக்கவேண்டிவருகிறீர்,செய்யவேண்டிவருகிறீர்,அழவேண்டிவருகிறீர்,சாகவேண்டிவருகிறீர்,தின்கவேண்டிவருகிறீர்,நிற்கவேண்டிவருகிறீர்,கற்கவேண்டிவருகிறீர்,செல்லவேண்டிவருகிறீர்,பெறவேண்டிவருகிறீர்,ஓடவேண்டிவருகிறீர்,சொல்லவேண்டிவருகிறீர்,போகவேண்டிவருகிறீர்,ஆகவேண்டிவருகிறீர்,நடக்கவேண்டிவருகிறீர்,எழவேண்டிவருகிறீர்,வளரவேண்டிவருகிறீர்,அலையவேண்டிவருகிறீர்,வரமாட்டார்கள்,ஆளவேண்டிவருகிறீர்,விடவேண்டிவருகிறீர்,கொள்ளவேண்டிவருகிறீர்,பயிலவேண்டிவருகிறீர், ,உண்ணவேண்டிவருகிறேன்,காணவேண்டிவருகிறேன்,கேட்கவேண்டிவருகிறேன்,கொடுக்கவேண்டிவருகிறேன்,செய்யவேண்டிவருகிறேன்,அழவேண்டிவருகிறேன்,சாகவேண்டிவருகிறேன்,தின்கவேண்டிவருகிறேன்,நிற்கவேண்டிவருகிறேன்,கற்கவேண்டிவருகிறேன்,செல்லவேண்டிவருகிறேன்,பெறவேண்டிவருகிறேன்,ஓடவேண்டிவருகிறேன்,சொல்லவேண்டிவருகிறேன்,போகவேண்டிவருகிறேன்,ஆகவேண்டிவருகிறேன்,நடக்கவேண்டிவருகிறேன்,எழவேண்டிவருகிறேன்,வளரவேண்டிவருகிறேன்,அலையவேண்டிவருகிறேன்,வரமாட்டான்,ஆளவேண்டிவருகிறேன்,விடவேண்டிவருகிறேன்,கொள்ளவேண்டிவருகிறேன்,பயிலவேண்டிவருகிறேன்\n",
            "'தேவை' : Correct\n",
            "\n",
            "Auto-corrected Paragraph:\n",
            "வணக்கம், எப்படி இருக்கீங்க? நான் உங்களை நேசிக்கிறேன். இந்த சூரியன் காலை எழும்பும் போது அதை பாத்து எனக்கு ரொம்ப சந்தோஷம் ஆகிறது. நமக்கும்  தேவை.\n"
          ]
        }
      ]
    }
  ]
}